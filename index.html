<!--
Google IO 2012/2013 HTML5 Slide Template

Authors: Eric Bidelman <ebidel@gmail.com>
         Luke Mahé <lukem@google.com>

URL: https://code.google.com/p/io-2012-slides
-->
<!DOCTYPE html>
<html>
<head>
  <title></title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

<slide class="logoslide nobackground">
  <article class="flexbox vcenter">
    <div style='margin: 0 0 2em 0'><img src="images/google_developers_logo.png"></div>
    <div style='margin: 0 0 1em 0;'>Move forward and back with the arrow keys</div>
    <div>Press F to find text within the slide deck</div>
  </article>
</slide>

<slide class="title-slide segue nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
  <hgroup class="auto-fadein">
    <h1 data-config-title><!-- populated from slide_config.json --></h1>
    <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
    <p data-config-presenter><!-- populated from slide_config.json --></p>
  </hgroup>
  <aside class="note"><p>
  Hi. I'm Justin Uberti, tech lead for WebRTC at Google.
  [cut to demo machine, showing Sam with Nexus, walking down hall]
  Sam Dutton, coming to you live from WebRTC on Chrome for Android
  [Sam walks up on stage]
  [Sam intro]
  We're here to show off some of the great stuff our team has been working on.
  </p></aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>Watch this presentation on YouTube</h2>
  </hgroup>
  <article>
    <iframe  width="730" style="width: 730px;" src="http://www.youtube.com/embed/p2HzZkd2A40"></iframe>
  </article>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div>Low cost, high quality audio and video communication</div>
    </article>
    <aside class="note"><p>
    So WebRTC is all about Real Time Communication, R T C. This is the ability to communicate live, exchanging audio, video, with someone as if they were right there next to you.
    </p></aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big">...and data!</div>
    </article>
    <aside class="note">
      <p>And we're also doing this for data communication, so that we can bring this same sort of liveness to all kinds of web apps, like games, remote desktop apps.</p>
<p> And we're building this capability into the fabric of the web, to make it a seamless part of your web experience.</p>
    </aside>
</slide>

<slide class="segue dark quote nobackground">
  <aside class="gdbar right bottom"><img src="images/google_developers_icon_128.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <q>
      WebRTC is a new front in the long war for an open and unencumbered web
    </q>
    <div class="author">
      Brendan Eich<br>
      &ndash; Mozilla CTO and inventor of JavaScript
    </div>
  </article>
  <aside class="note">
    <p>
    Now we think WebRTC is cool, but there are a lot of other people who are pretty excited about it as well. One of the reasons WebRTC is significant because by enabling real-time audio and video, it fills one of the few remaining gaps in the web platform, where proprietary native apps (like Skype) could do something the web couldn't do. Now we're able to turn this around, and create a web where every WebRTC-enabled browser  can communicate in real time to each other, just by loading a web page. (Freely available?)
   </p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>WebRTC on Chrome</h2>
  </hgroup>
  <article>
    <ul>
      <li>Bringing real-time communications to the web</li>
      <li>Building a state-of-the-art media stack into Chrome</li>
      <li>Developing a new communications platform</li>
    </ul>
  </article>
  <aside class="note">
    <p>So that's what WebRTC strives to do:</p>
    <ul>
      <li>to add the key browser APIs for communications into the web platform</li>
      <li>to build the best implementation of this within Chrome</li>
      <li>and then to use this to create a new communications ecosystem, of WebRTC-capable devices</li>
    </ul>
  </aside>
</slide>


<slide class="segue dark quote nobackground">
  <aside class="gdbar right bottom"><img src="images/google_developers_icon_128.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <q>Voice is just another JS application</q>
    <div class="author">
      Henning Schulzrinne<br>
      &ndash; CTO, US FCC
    </div>
  </article>
  <aside class="note">
    <p>This is a quote from the current FCC CTO, who sees WebRTC replacing traditional telephony, as voice calling becomes just another web app.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>WebRTC across platforms</h2>
  </hgroup>
  <article style="height: 100%; position: relative">
    <ul class="tight" xstyle='margin: 0 1em 0 0'>
      <li>Chrome</li>
      <li>Chrome for Android</li>
      <li>Firefox</li>
      <li>Opera</li>
      <li>Native <a href="https://code.google.com/p/libjingle/source/browse/trunk/talk/app/webrtc/java/src/org/webrtc/PeerConnection.java">Java</a> and Objective-C bindings</li>
    </ul>
    <img src="images/android.jpg" alt="Firefox/Chrome interoperability" style="position: absolute; right: 2em; top: -82px; width: 320px" />
    <img src="images/firefoxChrome.jpg" alt="Firefox/Chrome interoperability" style="position: absolute; bottom: 5em; width: 45%;" />
  </article>
  <aside><p>So we're working on delivering on that promise. And right now, you can write a single WebRTC app that connects Chrome, Chrome for Android, and Firefox, and soon, Opera.
      Just this week, Mozilla released Firefox 22 to Beta, the first version with WebRTC enabled, and this will be rolled out to all users shortly. So within a few weeks, there will be
    </p>
  </aside>
</slide>


<slide class="nobackground">
  <article class="fill flexbox vcenter">
       <div class="big"><b>1,000,000,000+</b></div>
       <div>WebRTC Endpoints</div>
  </article>
  <aside class="note">
  <p>Over one billion WebRTC-enabled users, which gives some idea of the size of this opportunity. In order to grow the ecosystem further, we're also providing official, supported native versions of WebRTC for Android, and very soon iOS.</p>
  </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
  <img src="images/logos.png" alt="Apps using WebRTC" />
  </article>
  <aside class="note">
    <p>So here are just a few of the companies that are going after this opportunity and building their businesses around WebRTC.</p>
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>The WebRTC APIs</h2>
    <h3></h3>
  </hgroup>
  <aside class="note">
  <p>So that's the vision for WebRTC. Now let's dig into the APIs that WebRTC provides.</p>'
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Three main tasks</h2>
  </hgroup>
    <article>
  <ul>
    <li>Acquiring audio and video</li>
    <li>Communicating audio and video</li>
    <li>Communicating arbitrary data</li>
  </ul>
    </article>
    <aside class="note">
    <p>We can divide up the functions provided by WebRTC into about 3 categories - getting access to audio and video streams, making a connection to another endpoint and sending those streams, and lastly, sending application data.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Three main JavaScript APIs</h2>
  </hgroup>
  <article>
  <ul>
    <li>MediaStream (aka getUserMedia)</li>
    <li>RTCPeerConnection</li>
    <li>RTCDataChannel</li>
  </ul>
  </article>
  <aside class="note">
    <p>These are handled by 3 different objects in WebRTC - MediaStream, RTCPeerConnection, and RTCDataChannel.
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>MediaStream</h2>
    <h3>Acquiring audio and video</h3>
  </hgroup>
  <aside class="note">
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>MediaStream</h2>
  </hgroup>
  <article>
    <ul>
      <li>Represents a stream of audio and/or video</li>
      <li>Can contain multiple 'tracks'</li>
      <li>Obtain a MediaStream with <code>navigator.getUserMedia()</code></li>
    </ul>
    <img src="images/mediaStream.png" alt="MediaStream diagram" style="width: 550px" />
  </article>
  <aside class="note">
  </aside>
</slide>

<!-- <slide class="nobackground">
  <article class="flexbox vcenter">
    <img src="images/mediaStream.png" alt="MediaStream diagram" style="width: 733px" />
  </article>
  </article>
  <aside class="note">
  </aside>
</slide> -->

<slide>
  <hgroup>
    <h2>MediaStream</h2>
    <h3>aka getUserMedia</h3>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
var constraints = {video: true};

function successCallback(stream) {
  var video = document.querySelector("video");
  video.src = window.URL.createObjectURL(stream);
}

function errorCallback(error) {
  console.log("navigator.getUserMedia error: ", error);
}

<b>navigator.getUserMedia(constraints, successCallback, errorCallback);</b>
</pre>
  </article>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <div class="bigger"><a href="http://www.simpl.info/gum" title="Simple getUserMedia demo">simpl.info/gum</a></div>
  </article>
  <aside class="note">
    <p>Chrome, Firefox, Opera, Chrome and Firefox on Android.</p>
    <p>If you run with HTTPS, or from an app, permission will only be asked for once.</p>
    <p>Likewise with Chrome apps that ask for "audioCapture" and"videoCapture" permissions.</p>
    <p>UI settings can be changed afterwards.</p>
  </aside>
</slide>

<!-- <slide class="nobackground">
  <hgroup>
    <h2>Multiple inputs</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <div id='multipleInputs'>
    <img id='nexusInput' src="images/nexus10.png" alt="Nexus 10" />
    <div>
    Microphone<br />
    →<br />
    Front camera<br />
    →<br />
    Rear camera<br />
    →<br />
    App sharing video<br />
    →<br />
    <br />
    Webcam video<br />
    ←<br />
    Stereo audio<br />
    ←
    </div>
  <img id='pixelInput' src="images/pixel.jpg" alt="Chromebook Pixel" />
  </div>
  </article>
  <aside class="note">
    <p>Chrome, Firefox, Opera, Chrome and Firefox on Android.</p>
  </aside>
</slide> -->

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://idevelop.github.com/ascii-camera/" title="getUserMedia video rendered as ASCII art">idevelop.github.com/ascii-camera</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://lli.web.fh-koeln.de/mocowe" title="getUserMedia used to control a slide deck">lli.web.fh-koeln.de/mocowe</a></div>
    </article>
    <aside class="note">
    </aside>
</slide> -->

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://www.shinydemos.com/facekat/" title="getUserMedia used to control a game">FaceKat</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://webcamtoy.com/app" title="getUserMedia photobooth, with effects">webcamtoy.com</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://www.soundstep.com/blog/experiments/jsdetection/" title="getUserMedia xylophone">soundstep.com/blog/experiments/jsdetection</a></div>
    </article>
    <aside class="note">
    </aside>
</slide> -->

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://www.simpl.info/headtrackr" title="getUserMedia with headtrackr.js face detection">simpl.info/headtrackr</a></div>
    </article>
    <aside class="note">
    <p>Check out the console for headtracking events!</p>
    </aside>
</slide> -->

<slide>
  <hgroup>
    <h2>Constraints</h2>
  </hgroup>
  <article>
    <ul>
      <li>Controls the contents of the MediaStream</li>
      <li>Media type, resolution, frame rate</li>
    </ul>
    <pre class="prettyprint" data-lang="javascript">
video: {
  mandatory: {
    minWidth: 640,
    minHeight: 360
  },
  optional [{
    minWidth: 1280,
    minHeight: 720
  }]
}
 </pre>
  </article>
</slide>

<slide>
  <hgroup>
  </hgroup>
    <article class="fill flexbox vcenter">
      <div><a href="https://simpl.info/getusermedia/constraints/" title="getUserMedia constraints demo">simpl.info/getusermedia/constraints</a></div>
    </article>
</slide>

<slide>
  <hgroup>
    <h2>getUserMedia + Web Audio</h2>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
// Success callback when requesting audio input stream
function gotStream(stream) {
    var audioContext = new webkitAudioContext();

    // Create an AudioNode from the stream
    var mediaStreamSource = audioContext.createMediaStreamSource(stream);

    // Connect it to the destination or any other node for processing!
    mediaStreamSource.connect(audioContext.destination);
}

navigator.webkitGetUserMedia({audio:true}, gotStream);
</pre>
  <p style='margin: 2em 0 0 0'>Make sure to enable Web Audio Input in about:flags!</p>

  </article>
  <aside class="note">
  <p>RTCPeerConnection will also accept Web Audio output.</p>
  </aside>
</slide>

 <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://www.webaudiodemos.appspot.com/AudioRecorder/index.html" title="Record audio">webaudiodemos.appspot.com/AudioRecorder</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>gUM screencapture</h2>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
var constraints = {
  video: {
    mandatory: {
      chromeMediaSource: 'screen'
    }
  }
};

navigator.webkitGetUserMedia(constraints, gotStream);
</pre>
<!-- <a href="https://simpl.info/screencapture/" title="Screen capture–RTCPeerConnection demo">simpl.info/screencapture</a> -->
  </article>
  <aside class="note">
    <p</p>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="https://html5-demos.appspot.com/static/getusermedia/screenshare.html" title="Screen sharing demo">gUM screencapture</a></div>
      <!-- <div><a href="http://updates.html5rocks.com/2012/12/Screensharing-with-WebRTC" title="HTML5 Rocks update demoing tab capture">Tab capture: chrome.tabCapture</a></div> -->
    </article>
    <aside class="note">
    <p>Extremely useful for doing IT support for your extended family!</p>
    </aside>
</slide>

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://webaudiodemos.appspot.com/pitchdetect/index.html" title="Pitch detection demo">webaudiodemos.appspot.com/pitchdetect</a></div>
    </article>
    <aside class="note">
    </aside>
</slide> -->

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://www.webaudiodemos.appspot.com/input/index.html" title="Web Audio effects demo">webaudiodemos.appspot.com/input</a></div>
    </article>
    <aside class="note">
    </aside>
</slide> -->

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://www.lab.aerotwist.com/webgl/audio-room" title="WebGL example">lab.aerotwist.com/webgl/audio-room</a></div>
    </article>
    <aside class="note">
    </aside>
</slide> -->

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://samdutton.net/backwards/" title="Record audio and play it backwards">samdutton.net/backwards</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

 -->

<!-- <slide>
  <hgroup>
    <h2>gUM ☞ Web Audio ☞ RTCPeerConnection</h2>
  </hgroup>
  <article>
  <p style="margin: 0 0 2em 0">Capture microphone input and stream it to a peer with processing applied:</p>
    <pre class="prettyprint" data-lang="javascript">
navigator.getUserMedia('audio', gotAudio);
function gotAudio(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();
  var peer = context.createMediaStreamDestination();
  microphone.connect(filter);
  filter.connect(peer);
  peerConnection.addStream(peer.stream);
}
</pre>

  <p style="margin: 2em 0 0 0"><a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html" title="W3C examples adapted from the MediaStream Processing API proposal">More Media Stream integration examples</a></p>

  </article>
  <aside class="note">
    <p>Already in experimental builds and working well.</p>
    <p>This is very powerful: effects into and out of RTCPeerConnection.</p>
    <p>'Join the boxes' architecture.</p>
  </aside>
</slide> -->

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>RTCPeerConnection</h2>
    <h3>Audio and video communication between peers</h3>
  </hgroup>
  <aside class="note">
    <p>This is the API for audio and video communication, to create a connection between peers.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Communicate Media Streams</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
    <div>
      <img style="float: left; width: 27%;" src="images/caller.jpg" alt="WebRTC video chat: caller" />
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; text-align: center;">
      →<br />
      getUserMedia<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>
      <img  style="float: left; position: relative; top: 38px; width: 35%;" src="images/callee.jpg" alt="WebRTC video chat: callee" />
    </div>
  </article>
  <aside class="note">
    On the surface, the API is simple - get access to MediaStreams via getUserMedia, then plug them into a PeerConnection, and they will get sent to another WebRTC endpoint automatically. And when we receive media from the remote side, this goes into new MediaStreams that can be rendered in our web page.
  </aside>
</slide>

<slide class="nobackground">
  <hgroup>
    <h2>RTCPeerConnection does a lot</h2>
  </hgroup>
    <article>
  <ul>
    <li>Signal processing</li>
    <li>Codec handling</li>
    <li>Peer to peer communication</li>
    <li>Security</li>
    <li>Bandwidth management</li>
  </ul>
    <p>...</p>
    </article>
    <aside class="note">
    <p>Under the hood though, RTCPeerConnection is doing a lot - processing audio and video to remove noise, compressing the data using codecs, setting up the peer to peer pathway through NATs and firewalls, encrypting the data, ensuring we use the right amount of bandwidth...</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>WebRTC architecture</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/webrtcArchitecture.png" alt="WebRTC architecture diagram" />
  </article>
  <aside class="note">
  <p>There's a lot of moving parts under the hood. Fortunately, with RTCPeerConnection, this is mostly abstracted away. You create a RTCPeerConnection, add your own MediaStreams to it, call a couple methods to set up the right parameters for the call, and off you go. Sam's going to now show us a super-simple example of RTCPeerConnection.'
  </aside>
</slide>

<!-- <slide>
  <hgroup>
    <h2>This is embarrassing...</h2>
  </hgroup>
  <article>
    <ul>
      <li>PeerConnection</li>
      <li>DeprecatedPeerConnection</li>
      <li>PeerConnection00</li>
      <li>In Chrome now: <strong>webkitRTCPeerConnection</strong></li>
      <li>When the dust settles: <strong>RTCPeerConnection</strong></li>
    </ul>
  </article>
</slide> -->

<slide>
  <hgroup>
    <h2>RTCPeerConnection sample</h2>
      </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
pc = new RTCPeerConnection(null);
pc.onaddstream = gotRemoteStream;
pc.addStream(localStream);
pc.createOffer(gotOffer);

function gotOffer(desc) {
  pc.setLocalDescription(desc);
  sendOffer(desc);
}

function gotAnswer(desc) {
  pc.setRemoteDescription(desc);
}

function gotRemoteStream(e) {
  attachMediaStream(remoteVideo, e.stream);
}
</pre>
  </article>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big"><a href="http://www.simpl.info/pc" title="Simple one-page RTCPeerConnection example">simpl.info/pc</a></div>
    </article>
    <aside class="note">
      <p>If you want to understand how WebRTC works, it's good to learn about RTCPeerConnection first, before you try to get your head around signaling mechanisms.</p>
      <p>This 'single page' demo does just that.</p>
      <p>It's very verbose: take a look at the console.</p>
      <p>Also take a look at chrome://webrtc-internals.</p>
    </aside>
</slide>

<!-- <slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div><a href="http://apprtc.appspot.com" title="Canonical RTCPeerConnection videochat example">apprtc.appspot.com</a></div>
    </article>
    <aside class="note">
    <p>This is the best place to start with a fully featured WebRTC app: RTCPeerConnection, with signaling provided by XHR and DataChannel.</p>
    </aside>
</slide> -->

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>RTCDataChannel</h2>
    <h3>Bidirectional communication of arbitrary data between peers</h3>
  </hgroup>
  <aside class="note">
    <p>The last API to talk about is RTCDataChannel.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Communicate arbitrary data</h2>
  </hgroup>
  <article class="fill flexbox vcenter">
  <div>

  <div style="float: left; width: 28%;">
    <img style="display: block; margin: 0 0 0.5em 0; position: relative; width: 100%;" src="images/jankInvadersScreenshot.jpg" alt="Game: caller" />
    <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship1";
    x: 24,
    y: 11,
    velocity: 7
  },
  ....
]
send(myData);
</div>
      </div>
      <div style="float: left; line-height: 2em; margin: 0 2em 0 2em; position: relative; text-align: center; top: 4em; width: 25%;">
      →<br />
      RTCDataChannel<br />
      +<br />
      RTCPeerConnection<br />
      ←
      </div>

      <div style="float: left; width: 28%;">
        <div style="background: #eee; font-family: 'Source Code Pro', 'Courier New', monospace; font-size: 0.5em; line-height: 1.2em; margin: 0 0 1em 0; padding: 1em; white-space: pre;">onreceivemessage = handle(data);
...
var myData = [
  {
    id: "ship7";
    x: 19,
    y: 4,
    velocity: 18
  },
  ....
]
send(myData);
</div>
        <img style="display: block; width: 100%;" src="images/jankInvadersScreenshotReversed.jpg" alt="Game: callee" />
      </div>

  </div>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>RTCDataChannel</h2>
  </hgroup>
  <article>
    <ul>
      <li>Same API as WebSockets</li>
      <li>Ultra-low latency</li>
      <li>Unreliable or reliable</li>
      <li>Secure</li>
    </ul>
  </article>
    <aside class="note">
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>RTCDataChannel API</h2>
  </hgroup>
  <article>
<pre class="prettyprint" data-lang="javascript">
var pc = new webkitRTCPeerConnection(servers,
  {optional: [{RtpDataChannels: true}]});

pc.ondatachannel = function(event) {
  receiveChannel = event.channel;
  receiveChannel.onmessage = function(event){
    document.querySelector("div#receive").innerHTML = event.data;
  };
};

sendChannel = pc.createDataChannel("sendDataChannel", {reliable: false});

document.querySelector("button#send").onclick = function (){
  var data = document.querySelector("textarea#send").value;
  sendChannel.send(data);
};
</pre>
  </article>
    <aside class="note">
    </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big"><a href="http://www.simpl.info/dc" title="Single page RTCDataChannel example">simpl.info/dc</a></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide class="nobackground">
  <article class="fill flexbox vcenter">
    <a class="big" href="http://www.sharefest.me/" title="Sharefest app">Sharefest</a>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Servers and Protocols</h2>
    <h3>Peer to peer &mdash; but we need servers  :^\</h3>
  </hgroup>
  <aside class="note">
      <p>So we just talked about how WebRTC can do all sorts of clever peer-to-peer stuff. But in order to bring up the peer-to-peer connection, we need servers to help coordinate things.
      The first thing we need to do is something we call signaling.</p>
  </aside>
</slide>
<!--
<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div>Peer to peer &mdash; but we need servers  :^\</div>
    </article>
    <aside class="note">
      <p>So discovery and signaling require intermediary servers to set up a call.</p>
      <p>At this point in history there's no way to say 'Exchange streaming data with my friend's computer!'</p>
    </aside>
</slide>
-->
<!-- <slide class="nobackground">
  <hgroup>
    <h2>Peer discovery</h2>
  </hgroup>
  <article>
    <ul>
      <li>Find peers (WebRTC clients)</li>
      <li>Coordinate communication</li>
    </ul>
  </article>
  <aside class="note">
    <p>This is the process of making contact with someone in order to begin communicating with them.</p>
    <p>If you use the telephone, you need a phone number -- and in terms of telephony, mechanisms to set up a call. </p>
    <p>Likewise for using chat on your computer. WebRTC is similar.</p>
    <p>A really simple example of a discovery mechanism is to share a URL. That's what's been done on several of the WebRTC demos. You can share the URL, then via a server establish some kind of communication channel.</p>
    <p>Just to reiterate: WebRTC does not specify how to do this.</p>
  </aside>
</slide> -->

<slide class="nobackground">
  <hgroup>
    <h2>Abstract Signaling</h2>
  </hgroup>
  <article>
    <ul>
      <li>Need to exchange 'session description' objects:</li>
      <ul class="tight">
      <li>What formats I support, what I want to send</li>
      <li>Network information for peer-to-peer setup</li>
      </ul>
      <li>Can use any messaging mechanism</li>
      <li>Can use any messaging protocol</li>
    </ul>
  </article>
  <aside class="note">
    <p>Signalling is the process of coordinating communication. Similar to, when you make a phone call, the phone system sends a message to the person you're calling indicating that there's an incoming call. Then, when you answer the call, a message is sent back indicating the call is live.</p>
    <p>The same is true for WebRTC. A message needs to get sent by each side indicating the parameters they want to use for the call. This is called a "session description", and it includes a bunch of details regarding codecs, encryption, network information, etc.</p>
    <p>The details aren't critical for most apps; they just need to exchange these messages in some way. The mechanism is up to the app - it can use WebSockets, Google Cloud Messaging, XHR, whatever it wants to use.</p>
    <p>Similarly, the exact protocol through which these are exchanged is also up to the app - many apps will send these messages as JSON, although some apps may use the standard SIP or XMPP protocols.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Signaling Diagram</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/jsep.png" alt="JSEP architecture diagram">
  </article>
      <aside class="note">
      <p>Here's a diagram that demonstrates this process. The caller sends a session description to its signaling server in the cloud, which then forwards this on to the callee. Similarly, the callee then sends its own session description back through the cloud to the caller. Once each side has given the session descriptions to RTCPeerConnection, the peer-to-peer link is established and media can flow.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>An RTCSessionDescription</h2>
  </hgroup>
  <article>
<pre class="prettyprint" data-lang="ugh">
v=0
o=- 7614219274584779017 2 IN IP4 127.0.0.1
s=-
t=0 0
a=group:BUNDLE audio video
a=msid-semantic: WMS
m=audio 1 RTP/SAVPF 111 103 104 0 8 107 106 105 13 126
c=IN IP4 0.0.0.0
a=rtcp:1 IN IP4 0.0.0.0
a=ice-ufrag:W2TGCZw2NZHuwlnf
a=ice-pwd:xdQEccP40E+P0L5qTyzDgfmW
a=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level
a=mid:audio
a=rtcp-mux
a=crypto:1 AES_CM_128_HMAC_SHA1_80 inline:9c1AHz27dZ9xPI91YNfSlI67/EMkjHHIHORiClQe
a=rtpmap:111 opus/48000/2
...
</pre>
  </article>
    <aside class="note">
    <p>In case you're wondering, the insides of a RTCSessionDescription look like this. While apps can manipulate this information for fine-grained control, we've tried to make it so that most apps don't need to worry about this.</p>
    </aside>
</slide>

<!-- <slide>
  <hgroup>
    <h2>Making the connection</h2>
  </hgroup>
  <article class="flexbox vcenter">
<a href="http://www.w3.org/TR/webrtc/#simple-example" title="Simple W3C signaling example">w3.org/TR/webrtc/#simple-example</a>
  </article>
</slide> -->

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>STUN and TURN</h2>
    <h3>P2P in the age of firewalls and NATs</h3>
  </hgroup>
  <aside class="note">
      <p>The other place where servers come into play is in figuring out how to route the peer-to-peer connection.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>An ideal world</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/noSTUNorTURN.png" alt="Data pathways between peers if there were no NATs or firewalls" style="position: relative; top: -30px">
  </article>
    <aside class="note">
      <p>In an ideal world, life would be simple - each endpoint could tell the other side its IP address, and a direct link could easily be established.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>The real world</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/firewall.png" alt="Data pathways showing firewalls" style="position: relative; top: -26px">

  </article>
   <aside class="note">
   <p>But in the age of NAT, this just isn't the case. Most users are behind what's called a NAT, which hands out a private IP address that can't be used for communication. Without a public address, there's no way to set up a peer-to-peer link.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>STUN</h2>
  </hgroup>
  <article>
    <ul>
      <li>Tell me what my public IP address is</li>
      <li>Simple server, cheap to run</li>
      <li>Data flows peer-to-peer</li>
    </ul>
  </article>
   <aside class="note">
   <p>To solve this, we use a technology called STUN. If we tell WebRTC about the location of a STUN server, it can ask the STUN server to tell it the right public address to use. The STUN server's job is simple - it just looks at where an incoming request is coming from, and sends that address back in the response.  WebRTC can then exchange that public address with the other side and use that to set up a direct link.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>STUN</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/stun.png" alt="Data pathways between peers using STUN" style="position: relative; top: -50px">
  </article>
      <aside class="note">
      <p>Here's a diagram of that in action. Each side asks its STUN server what its public address is, and then the peers can directly connect. Now, this technique usually works, but depending on the kind of NAT or firewall that is present, there are some cases where it doesn't.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>TURN</h2>
  </hgroup>
  <article>
    <ul>
      <li>Provide a cloud fallback if peer-to-peer communication fails</li>
      <li>Data is sent through server, uses server bandwidth</li>
      <li>Ensures the call works in almost all environments</li>
    </ul>
  </article>
      <aside class="note">
      <p>The other technique that WebRTC can use is called TURN. A TURN server is essentially a server that relays the data an endpoint is trying to send to the other side. Because it has a public address already, it's easy to contact, so the connection always works, even in cases where the endpoint is behind a restrictive firewall or proxy. The downside is that all the data traffic has to go through the relay, so there's a nontrivial bandiwdth cost.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>TURN</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/STUNandTURN.png" alt="Data pathways between peers using TURN" style="left: 1px; position: relative; top: -47px">
  </article>
   <aside class="note">
      <p>Here's a diagram of that in action. We tried to use STUN, but it didn't quite work right. So instead, each side contacted its own TURN server, and then data flow goes from each endpoint, through the TURN server, to the other side.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>ICE</h2>
  </hgroup>
  <article>
     <ul>
        <li><a href="http://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment" title="Wikipedia ICE article">ICE</a>: a framework for connecting peers</li>
      <li>Tries to find the best path for each call</li>
      <li>Vast majority of calls can use STUN (webrtcstats.com):
    </ul>
 <img src="images/icestats.png" alt="Data pathways between peers using TURN" style="left: 1px; position: relative; left: 200px">
  </article>
  <aside class="note">
      <p>On one hand, we have STUN, which is cheap, but doesn't always work. And on the other, we have TURN, which always works, but has an operational cost. Fortunately, we can get the best of both worlds. WebRTC uses a mechanism called ICE, Interactive_Connectivity_Establishment, to quickly figure out the best path. It tries all the possibilities in parallel and settles on the cheapest one that actually works.
          Based on some measurements done by the folks at WebRTCStats.com, about 86% of calls will work with just STUN, only 1 in 7 calls need to be routed through a TURN server.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Deploying STUN/TURN</h2>
  </hgroup>
  <article>
     <ul>
        <li>stun.l.google.com:19302</li>
        <li>WebRTC stunserver, turnserver</li>
        <li>rfc5766-turn-server</li>
        <li>restund</li>
    </ul>
  </article>
  <aside class="note">
      <p>For basic testing, we run a public STUN server, and we also include source code for STUN and TURN servers in the WebRTC tree. For running a production STUN/TURN service, we recommend using rfc5766-turn-server, which has source code and AWS VM images, or restund, available as source code.</p>
    </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Security</h2>
  </hgroup>
  <aside class="note">
  <p>One question that comes up about WebRTC is how security is handled.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Security throughout WebRTC</h2>
  </hgroup>
  <article>
  <ul>
    <li>Mandatory encryption for media and data</li>
    <li>Secure UI, explicit opt-in</li>
    <li>Sandboxed, no plugins</li>
    <li><a href="http://www.ietf.org/proceedings/82/slides/rtcweb-13.pdf" title="Security Architecture slides">WebRTC Security Architecture</a></li>
  </ul>
  </article>
<aside class="note">
    <p>We've taken care to build security into WebRTC from the very beginning; all media and data is encrypted and protected, we require opt-in from the user before enabling their mic and camera, and WebRTC runs in the Chrome sandbox, which means that even if someone sends malicious data to WebRTC, the browser will be unaffected.</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Secure pathways</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/securePathways.png" alt="Secure pathways between peers" style="position: relative; top: -10px">
  </article>
  <aside class="note">
    <p>The only thing an app developer needs to do to ensure WebRTC security, is to use HTTPS when sending signaling data. In this diagram, the signaling pathways are protected using HTTPS, and the media and data are protected using the standard SRTP and DTLS mechanisms.</p>
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Architectures</h2>
  </hgroup>
  <aside class="note">
  <p>Another question that developers have is how to architect their service.</p>
  </aside>
</slide>

<slide>
<hgroup>
    <h2>Peer to peer: one-to-one call</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/topologyOneToOne.png" alt="Topology diagram: one to one">
  </article>
    <aside class="note">
  <p>In the simplest case, a point-to-point call, the endpoints are directly connected.</p>
  </aside>
</slide>

<slide>
<hgroup>
    <h2>Mesh: small N-way call</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/topologyFullMesh.png" alt="Topology: full mesh" style='width: 450px;'>
  </article>
   <aside class="note">
  <p>For a multi-user call, we can extend that, and have every endpoint connect to every other endpoint. Note that this means that each endpoint is sending multiple copies of the data, which leads to higher CPU and network utilization. Depending on what kind of media you are sending, this becomes unworkable after a certain number of participants, especially if you have mobile clients in the mix.</p>
  </aside>
</slide>

<slide>
<hgroup>
    <h2>Star: medium N-way call</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/topologyOneToThree.png" alt="Topology diagram: one to three" style='width: 450px;'>
  </article>
     <aside class="note">
  <p>Another option is to designate one endpoint as a "focus", and have that endpoint handle the task of distributing data to the others; the application can choose the most capable endpoint to serve as the focus. This tends to work better than a mesh, but still runs into trouble when handling multiple HD video streams.</p>
  </aside>
</slide>

<slide>
<hgroup>
    <h2>MCU: large N-way call</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <img src="images/topologyMCU.png" alt="Topology: MCU" style='width: 600px;'>
  </article>
    <aside class="note">
  <p>The most robust solution is to use what's called a MCU, or multipoint control unit. This is a server that's made specifically to do distribution of media, and can handle large numbers of participants; it can also do smart things like selective stream forwarding, mixing of the audio or video, or recording.</p>
  </aside>
</slide>

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Beyond browsers</h2>
  </hgroup>
  <aside class="note">
      <p></p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Phones and more</h2>
  </hgroup>
  <article>
  <ul>
    <li>Easy to interoperate with non-browser devices</li>
    <ul>
    <li><a href="https://code.google.com/p/sipml5/" title="">sipML5</a> open source JavaScript SIP client</li>
      <li><a href="http://phono.com/" title="Phono SDK site">Phono</a> open source JavaScript phone API</li>
      <li><a href="http://zingaya.com/product/" title="Zingaya SDK site">Zingaya</a> embeddable phone widget</li>
      </ul>
    </ul>
  </article>
    <aside class="note">
      <p>WebRTC has been designed with standards in mind, which means it's easy for it to communicate with non-WebRTC devices, like phones. There are a bunch of libraries out there that allow you to do this with just a few lines of code. Let's take a look at a demo from Zingaya.'</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Telephony</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <div class='big'><a href="http://demos.zingaya.com/webrtc-pstn/" title="Zingaya WebRTC PSTN demo">Zingaya PSTN</a></div>
  </article>
  <aside class='note'>
    <p>631-403-9000</p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Tethr</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <a href="http://tethr.tumblr.com" title="WebRTC API documentation"><img style="height: 100%" src="images/tethr.jpg" alt="Tethr in action at Google I/O 2012" /></a>
  </article>
    <aside class="note">
      <p>At Google I/O last year Voxeo demonstrated a framework for disaster communications:</p>
      <p>Set up an OpenBTS cell to enable communications between feature phones and computers via WebRTC.</p>
      <p>Telephone communication without a carrier!</p>
    </aside>
</slide>

<!-- <slide>
  <hgroup>
    <h2>Signalling: find me a candidate</h2>
  </hgroup>
  <article>
    <ol>
      <li>Caller creates RTCPeerConnection object.</li>
      <li>If success, callback passed IceCandidate.</li>
      <li>Caller sends IceCandidate to callee.</li>
      <li>Callee creates a new remote IceCandidate, adds to remote description.</li>
      <li>Ping!</li>
    </ol>
  </article>
    <aside class="note">
    <p>When the RTCPeerConnection object has been successfully created by the caller, the onIceCallback callback is called (in this example).</p>
      <p>This callback is passed a candidate object, which the caller then serialises and sends to the callee.</p>
      <p>On receipt of this message, the callee creates a new IceCandidate and calls processIceMessage() on it.</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>Signalling: make me an offer</h2>
  </hgroup>
  <article>
    <ol>
      <li>Caller sends offer.</li>
      <li>Callee receives offer.</li>
      <li>Callee sends answer.</li>
      <li>Caller receives answer.</li>
      <li>Ping!</li>
    </ol>
  </article>
    <aside class="note">
      <ol>
        <li>The caller creates an RTCPeerConnection object and sets the local description.</li>
        <li>Caller uses RTCPeerConnection to create an offer. An offer is a blob -- a local session description in SDP format.</li>
        <li>The offer is serialised and communicated via the signaling channel to the callee. </li>
        <li>When the callee gets the offer message, they create an RTCPeerConnection object and set the remote description from the offer.</li>
        <li>The callee then uses its RTCPeerConnection to creates an answer (passing it the offer) and sends that back to the caller.</li>
      </ol>
    </aside>
</slide>
 -->

<slide class="segue dark nobackground">
  <aside class="gdbar"><img src="images/google_developers_icon_128.png"></aside>
  <hgroup class="auto-fadein">
    <h2>Building a WebRTC app</h2>
  </hgroup>
  <aside class="note">
    <p>We have tools to help you!</p>
  </aside>
</slide>

<slide class="nobackground">
 <hgroup>
    <h2>chrome://webrtc-internals</h2>
    </hgroup>
     <article class="fill flexbox vcenter">
    <img src="images/internals.png" alt="chrome://webrtc-internals screenshot" style="border: 1px solid #4444; position: relative; top: -48px; left: -54px;" />
</article>
    <aside class="note">
    <p>One tool</p>
    </aside>
</slide>

<slide class="nobackground">
<hgroup>
    <h2><a href="https://code.google.com/p/webrtc/source/browse/trunk/samples/apprtc/js/base/adapter.js">adapter.js</a></h2>
    </hgroup>
    <article>
    <p>Lets you use the same code in all browsers:</p>
      <ul>
        <li>Removes vendor prefixes</li>
        <li>Abstracts Chrome/Firefox differences</li>
        <li>Minimizes effects of spec churn</li>
       </ul>
  </article>
  <aside class="note">
  </aside>
</slide>

<slide class="nobackground red">
    <article class="fill flexbox vcenter">
      <div class="big"><strong>This is doing my head in.</strong></div>
    </article>
    <aside class="note">
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>JavaScript frameworks</h2>
  </hgroup>
  <article>
    <ul>
      <li>Video chat:</li>
      <ul>
      <li><a href="https://github.com/henrikjoreteg/SimpleWebRTC" title="SimpleWebRTC github repository">SimpleWebRTC</a></li>
      <li><a href="https://github.com/priologic/easyrtc" title="easyRTC github repository">easyRTC</a></li>
      <li><a href="https://github.com/webRTC/webRTC.io" title="webRTC.io github repository">webRTC.io</a></li>
      </ul>
      <li>Peer-to-peer data:</li>
      <ul>
      <li><a href="http://peerjs.com/" title="PeerJS site">PeerJS</a></li>
      <li><a href="https://github.com/peer5/sharefest" title="Sharefest github repository">Sharefest</a></li>
      </ul>
    </ul>
  </article>
    <aside class="note">
    </aside>
</slide>


<!-- <slide>
  <hgroup>
    <h2>SimpleWebRTC</h2>
    <h3>HTML</h3>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="html">
&lt;!DOCTYPE html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;script src="http://simplewebrtc.com/latest.js"&gt;&lt;/script&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;div id="localVideo"&gt;&lt;/div&gt;
        &lt;div id="remoteVideos"&gt;&lt;/div&gt;
    &lt;/body&gt;
&lt;/html&gt;
</pre>
  </article>
</slide> -->

<slide>
  <hgroup>
    <h2>SimpleWebRTC</h2>
    <h3>Easy peer-to-peer video and audio</h3>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
var webrtc = new WebRTC({
  localVideoEl: 'localVideo',
  remoteVideosEl: 'remoteVideos',
  autoRequestMedia: true
});

webrtc.on('readyToCall', function () {
    webrtc.joinRoom('My room name');
});
</pre>
  </article>
</slide>


<slide>
  <hgroup>
    <h2>PeerJS</h2>
    <h3>Easy peer-to-peer data</h3>
  </hgroup>
  <article>
    <pre class="prettyprint" data-lang="javascript">
var peer = new Peer('someid', {key: 'apikey'});
peer.on('connection', function(conn) {
  conn.on('data', function(data){
    // Will print 'hi!'
    console.log(data);
  });
});

// Connecting peer
var peer = new Peer('anotherid', {key: 'apikey'});
var conn = peer.connect('someid');
conn.on('open', function(){
  conn.send('hi!');
});

</pre>
  </article>
</slide>

<slide>
  <hgroup>
    <h2>Services</h2>
  </hgroup>
  <article>
  <ul><li>Complete video services:</li>
  <ul>
    <li><a href="http://www.tokbox.com/" title="Tokbox site">OpenTok</a> (acquired by Telefonica Digital)</li>
    <li><a href="http://www.vline.com/" title="vLine">vLine</a></li>
  </ul>
    </ul>
        <img src="images/networkmap.png" alt="Data center locations" style="" />
  </article>
    <aside class="note">
      <p>Javascript frameworks make writing apps easier, but they don't handle some of the more complicated aspects, like signaling and TURN servers. Fortunately, there are a couple turnkey WebRTC services out there that take care of all of this for you. You can sign up for these services, get an API key, and then make calls using their deployed infrastructure; they also offer UI components that can easily be integrated into your application.</p>
    </aside>
</slide>

<!-- <slide>
  <hgroup>
    <h2>Don't forget the C++!</h2>
  </hgroup>
  <article class="flexbox vcenter">
    <a href="http://www.webrtc.org/reference/webrtc-internals" title="WebRTC API documentation">webrtc.org/reference/webrtc-internals</a>
  </article>
    <aside class="note">
      <p>The WebRTC C++ APIs mean you can build a WebRTC client on a server -- check out the example in the webrtc.org source repository.</p>
      <p>Also a Qt/C++ demo on YouTube.</p>
    </aside>
</slide> -->

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class='big'><a href="http://apprtc.appspot.com/?r=io&hd=true" title="">Chris Wilson <strong>LIVE!</strong></a></div>
    </article>
    <aside class="note">
      <p>Before we wrap up, we have a special treat for you. I'd like to introduce Chris Wilson - a colleague of ours, who worked on the original Mosaic browser, and is a bit of a musician. Chris is joining us today, via WebRTC, to show off our support for HD video, and crystal clear, fullband audio. Take it away, Chris!</p>
    </aside>
</slide>

<slide>
  <hgroup>
    <h2>More Information</h2>
  </hgroup>
  <article>
  <ul>
    <li>Justin Uberti: <a href="http://www.youtube.com/watch?v=E8C8ouiXHHk" title="Video of Google I/O 2012 presentation">Google I/O presentation video</a></li>
    <li>Cullen Jennings video: <a href="http://vimeo.com/47682405" title="IETF and W3C standardisation discussion">HTML5 WebRTC</a></li>
    <li>HTML5 Rocks:</li>
    <ul>
      <li><a href="http://www.html5rocks.com/en/tutorials/getusermedia/intro/" title="HTML5 Rocks article about getUserMedia">Capturing audio and video in HTML5</a></li>
      <li><a href="http://www.html5rocks.com/en/tutorials/webrtc/basics/" title="HTML5 Rocks article about WebRTC">Getting Started With WebRTC</a></li>
      <li><a href="http://www.html5rocks.com/en/search?q=webrtc" title="HTML5 content tagged WebRTC">Updates</a></li>
    </ul>
    <li>...and a book: <a href="http://www.webrtcbook.com" title="WebRTC ebook download">webrtcbook.com</a></li>
  </ul>
  </article>
<aside class="note">
    <p></p>
  </aside>
</slide>

<slide>
  <hgroup>
    <h2>Contact Us</h2>
  </hgroup>
  <article>
  <ul>
    <li><a href="webrtc.org" title="WebRTC project website">webrtc.org</a></li>
    <li><a href="https://groups.google.com/forum/?fromgroups#!forum/discuss-webrtc" title="WebRTC discussion group">discuss-webrtc</a></li>
    <li><a href="https://plus.sandbox.google.com/113817074606039822053/posts" title="WebRTC on Google+">+webrtc</a></li>
      <li><a href="https://twitter.com/webrtc" title="WebRTC on Twitter">@webrtc</a></li>
      <li>  <a href="http://www.crbug.com/new" title="Report Chrome bugs and feature requests">crbug.com/new</a></li>
  </ul>
  </article>
<aside class="note">
    <p>webrtc.org has a blog, links to demos, documentation and links to code repositories</p>
    <p>...and follow Justin Uberti and Serge Lachapelle on Google+</p>
  </aside>
</slide>


<slide class="segue dark quote nobackground">
  <aside class="gdbar right bottom"><img src="images/google_developers_icon_128.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <q>WebRTC and HTML5 could enable the same transformation for real-time communications that the original browser did for information.</q>
    <div class="author">
      Phil Edholm<br>
      &mdash; NoJitter
    </div>
  </article>
  <aside class="note">
    <section>
      <ul>
        <li>So now it's your turn. We've built this technology into the web so that any developer can take advantage of real-time communications, and we can't wait to see what you do with it.</li>
      </ul>
    </section>
  </aside>
</slide>

<slide class="nobackground">
    <article class="fill flexbox vcenter">
      <div class="big"><a href="http://io13webrtc.appspot.com" title="These slides online">io13webrtc.appspot.com</a></div>
    </article>
    <aside class="note">
    Once again, the link to the slides.
    </aside>
</slide>

<slide class="thank-you-slide segue nobackground">
  <aside class="gdbar right"><img src="images/google_developers_icon_128.png"></aside>
  <article class="flexbox vleft auto-fadein">
    <h2>&lt;Thank You!&gt;</h2>
  </article>
  <p class="auto-fadein" data-config-contact>
    <!-- populated from slide_config.json -->
  </p>
</slide>

<slide class="logoslide dark nobackground">
  <article class="flexbox vcenter">
    <span><img src="images/google_developers_logo_white.png"></span>
  </article>
</slide>

<slide class="backdrop"></slide>

</slides>

<div id="find" style="display: none">
  <input autocomplete="on" list="datalist" type="search"><button>Find</button>
  <datalist id="datalist"></datalist>
</div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-41621713-1', 'io13webrtc.appspot.com');
  ga('send', 'pageview');

</script>

<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body>
</html>
